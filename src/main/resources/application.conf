mantis {
  # Identifier used when connecting to other clients
  client-id = "mantis"

  # Version string (reported by an RPC method)
  client-version = "mantis/v0.1"

  # Base directory where all the data used by the node is stored, including blockchain data and private keys
  datadir = ${user.home}"/.mantis"

  # The unencrypted private key of this node
  node-key-file = ${mantis.datadir}"/node.key"

  # timeout for shutting down the ActorSystem
  shutdown-timeout = "15.seconds"

  # Whether to run Mantis in test mode (similar to --test flag in cpp-ethereum).
  # When set, test validators and consensus are used by this node.
  # It also enables test_ RPC endpoints.
  testmode = false

  # one of the algorithms defined here:
  # https://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#SecureRandom
  # Uncomment this to specify, otherwise use the default implementation
  # secure-random-algo = "NativePRNG"

  keyStore {
    # Keystore directory: stores encrypted private keys of accounts managed by this node
    keystore-dir = ${mantis.datadir}"/keystore"

    # Enforces minimal length for passphrase of this keystore
    minimal-passphrase-length = 7

    # Allows possibility for no passphrase
    # If passphrase is set it must be greater than minimal-passphrase-length
    allow-no-passphrase = true
  }

  network {
    # Ethereum protocol version
    protocol-version = 63

    server-address {
      # Listening interface for Ethereum protocol connections
      interface = "0.0.0.0"

      # Listening port for Ethereum protocol connections
      port = 9076
    }

    discovery {

      # Turn discovery of/off
      discovery-enabled = true

      # Listening interface for discovery protocol
      interface = "0.0.0.0"

      # Listening port for discovery protocol
      port = 30303

      # Set of initial nodes
      bootstrap-nodes = [
        "enode://e809c4a2fec7daed400e5e28564e23693b23b2cc5a019b612505631bbe7b9ccf709c1796d2a3d29ef2b045f210caf51e3c4f5b6d3587d43ad5d6397526fa6179@174.112.32.157:30303",
        "enode://6e538e7c1280f0a31ff08b382db5302480f775480b8e68f8febca0ceff81e4b19153c6f8bf60313b93bef2cc34d34e1df41317de0ce613a201d1660a788a03e2@52.206.67.235:30303",
        "enode://5fbfb426fbb46f8b8c1bd3dd140f5b511da558cd37d60844b525909ab82e13a25ee722293c829e52cb65c2305b1637fa9a2ea4d6634a224d5f400bfe244ac0de@162.243.55.45:30303",
        "enode://42d8f29d1db5f4b2947cd5c3d76c6d0d3697e6b9b3430c3d41e46b4bb77655433aeedc25d4b4ea9d8214b6a43008ba67199374a9b53633301bca0cd20c6928ab@104.155.176.151:30303",
        "enode://814920f1ec9510aa9ea1c8f79d8b6e6a462045f09caa2ae4055b0f34f7416fca6facd3dd45f1cf1673c0209e0503f02776b8ff94020e98b6679a0dc561b4eba0@104.154.136.117:30303",
        "enode://72e445f4e89c0f476d404bc40478b0df83a5b500d2d2e850e08eb1af0cd464ab86db6160d0fde64bd77d5f0d33507ae19035671b3c74fec126d6e28787669740@104.198.71.200:30303",
        "enode://5cd218959f8263bc3721d7789070806b0adff1a0ed3f95ec886fb469f9362c7507e3b32b256550b9a7964a23a938e8d42d45a0c34b332bfebc54b29081e83b93@35.187.57.94:30303",
        "enode://39abab9d2a41f53298c0c9dc6bbca57b0840c3ba9dccf42aa27316addc1b7e56ade32a0a9f7f52d6c5db4fe74d8824bcedfeaecf1a4e533cacb71cf8100a9442@144.76.238.49:30303",
        "enode://f50e675a34f471af2438b921914b5f06499c7438f3146f6b8936f1faeb50b8a91d0d0c24fb05a66f05865cd58c24da3e664d0def806172ddd0d4c5bdbf37747e@144.76.238.49:30306",
        "enode://95636c71626ead0ee8dee7ba7cd3bb30f2beb6c25736366c570b072b820a28e5bcf16f06cbe93a912879be98aff93450b04dc1ad6b36dac0b43d8d4959303340@34.202.158.155:30304",
        "enode://fa3e2ebfdea1d38c8eca9b55b21aa4332646ddbc4f3c581cd50d320aebab05efed7f05ea7aa4b2a559aaaf91f19fc8766b87bf9d2aabb3fa2dee6e99ab15db1f@45.56.112.78:30304",
        "enode://a9705294408fc4374f7782be4304bafcffc8fb5da1c9469107c6f23f01ac8e7413a3501f33099636e336ac7ecf3a2d4175e79f6b12f29f9c8e3106b342973a12@94.130.140.225:30304",
        "enode://6960dd938eeb38deecfd5c960d14b07135977f3162f284ba416b7b463ccb15799a23efb462645c3b4db8a0d466e25378e3019ad6a10c1cd2dcdef9a30ed9396e@94.23.45.111:30303",
        "enode://4f6233f9371432e33b1536b9a03d9623eb1fd7988fd6497d21f13abda1ef99e0971b08d1e82aa484c26443813367f99f6ee185c930622ddb25a473ce07f59734@151.80.42.214:34703",
        "enode://4c560ce2e8293df3d0bce936f7d2a59baec583f43ddffb83e6ee61f7e6193cfa5c8d945df2db016e9e0a1e5613fb98c337a4e26f471ead972675ba847b36a3a6@45.32.155.170:30303",
        "enode://88e512d85ad930f3845a9daa910f7cff47e7d2556329d670d9428a84b9b066b19bb6838557056bc7c57a418b97b706c1fad106a2bd135ed478d086dfc0bfc4f9@80.211.156.224:30304",
        "enode://b7eff3b8c349835bf6b7ab869ddcf17e7445e1e8ce33f3356afb4b4c8a1fc97009f864636cc359267eccf5170404c2596d6d3502758f0705f0a27e08568d7185@37.19.7.83:30303",
        "enode://4bafe073023f2fe2791f5d2e7b408b673f8e0cf0f5118911e221ca7070ed0de87c567dbf6afdfc21154f3fe9b132aaaf3ceff5169fc8669bcbbfa4ba1a08cd83@37.19.7.86:30303",
        "enode://5a105e4b17ea0e5ece607841a183a259a0ccc3bea7f4811b23927dd20ee0f7fc033826d902a7ee1fab4e904722188b61891bed3dd28c380257c4c4681f873683@172.104.106.83:30304",
        "enode://21beff7f1fc241c60bf0e14f41bda370ef7442d544e203fbc4c9a50793e3b66ce151726851b105f76b578fbe11c56a80b0c64fd5a3482f1370174ebb70d920fd@106.14.186.127:50505"
      ]

      # Maximum discovered nodes stored (TODO: remove me once full protocol is in place)
      nodes-limit = 1000

      # Initial delay for discovery scan
      scan-initial-delay = 20.seconds

      # Scan interval for discovery
      scan-interval = 30.seconds

      # Discovery message expiration time
      message-expiration = 90.minutes

      # (TODO: remove me once full protocol is in place)
      scan-max-nodes = 20

      # (TODO: remove me once full protocol is in place)
      max-sent-neighbours = 10
    }

    known-nodes {
      # How often known nodes updates are persisted to disk
      persist-interval = 20.seconds

      # Maximum number of persisted nodes
      max-persisted-nodes = 200
    }

    peer {
      # Retry delay for failed attempt at connecting to a peer
      connect-retry-delay = 1 minute

      # Maximum number of reconnect attempts after the connection has been initiated.
      # After that, the connection will be dropped until its initiated again (eg. by peer discovery)
      connect-max-retries = 1

      disconnect-poison-pill-timeout = 5 seconds

      wait-for-hello-timeout = 3 seconds

      wait-for-status-timeout = 30 seconds

      wait-for-chain-check-timeout = 15 seconds

      wait-for-handshake-timeout = 3 seconds

      wait-for-tcp-ack-timeout = 5 seconds

      # Maximum block headers in a single response message (as a blockchain host)
      max-blocks-headers-per-message = 100

      # Maximum block bodies in a single response message (as a blockchain host)
      max-blocks-bodies-per-message = 100

      # Maximum transactions receipts in a single response message (as a blockchain host)
      max-receipts-per-message = 100

      # Maximum MPT components in a single response message (as a blockchain host)
      max-mpt-components-per-message = 200

      # Maximum number of peers this node can connect to
      max-outgoing-peers = 40

      # Maximum number of peers that can connect to this node
      max-incoming-peers = 5

      # Maximum number of peers that can be connecting to this node
      max-pending-peers = 5

      # Ethereum network identifier:
      # 1 - mainnet, 2 - morden
      network-id = 1

      # Initial delay before connecting to nodes
      update-nodes-initial-delay = 5.seconds

      # Newly discovered nodes connect attempt interval
      update-nodes-interval = 10.seconds

      # Peer which disconnect during tcp connection becouse of too many peers will not be retried for this short duration
      short-blacklist-duration = 6.minutes

      # Peer which disconnect during tcp connection becouse of other reasons will not be retried for this long duration
      # other reasons include: timeout during connection, wrong protocol, incompatible network
      long-blacklist-duration = 30.minutes
    }

    rpc {
      http {
        # JSON-RPC mode
        # Available modes are: http, https
        # Choosing https requires creating a certificate and setting up 'certificate-keystore-path' and
        # 'certificate-password-file'
        # See: https://github.com/input-output-hk/mantis/wiki/Creating-self-signed-certificate-for-using-JSON-RPC-with-HTTPS
        mode = "http"

        # Whether to enable JSON-RPC HTTP(S) endpoint
        enabled = true

        # Listening address of JSON-RPC HTTP(S) endpoint
        interface = "localhost"

        # Listening port of JSON-RPC HTTP(S) endpoint
        port = 8546

        # Path to the keystore storing the certificates (used only for https)
        # null value indicates HTTPS is not being used
        certificate-keystore-path = null

        # Type of certificate keystore being used
        # null value indicates HTTPS is not being used
        certificate-keystore-type = null

        # File with the password used for accessing the certificate keystore (used only for https)
        # null value indicates HTTPS is not being used
        certificate-password-file = null

        # Domains allowed to query RPC endpoint. Use "*" to enable requests from
        # any domain.
        cors-allowed-origins = []
      }

      ipc {
        # Whether to enable JSON-RPC over IPC
        enabled = true

        # Path to IPC socket file
        socket-file = ${mantis.datadir}"/mantis.ipc"
      }

      # Enabled JSON-RPC APIs over the JSON-RPC endpoint
      # Available choices are: eth, web3, net, personal, test, daedalus, iele
      apis = "eth,web3,net,personal,daedalus,debug"

      # Maximum number of blocks for daedalus_getAccountTransactions
      account-transactions-max-blocks = 50000

      net {
        peer-manager-timeout = 5.seconds
      }

      miner-active-timeout = 5.seconds
    }
  }

  txPool {
    # Maximum number of pending transaction kept in the pool
    tx-pool-size = 1000

    pending-tx-manager-query-timeout = 5.seconds

    transaction-timeout = 2.minutes

    # Used in mining (ethash) / forging (atomix-raft)
    get-transaction-from-pool-timeout = 5.seconds
  }

  consensus {
    # Miner's coinbase address
    # Also used in non-Ethash consensus.
    coinbase = "0011223344556677889900112233445566778899"

    # Extra data to add to mined blocks
    header-extra-data = "mantis"

    # This determines how many parallel eth_getWork request we can handle, by storing the prepared blocks in a cache,
    # until a corresponding eth_submitWork request is received.
    #
    # Also used by the generic `BlockGenerator`.
    block-cashe-size = 30

    # See io.iohk.ethereum.consensus.Protocol for the available protocols.
    # Declaring the protocol here means that a more protocol-specific configuration
    # is pulled from the corresponding consensus implementation.
    # For example, in case of ethash, a section named `ethash` is used.
    protocol = ethash

    # If true then the consensus protocol uses this node for mining.
    # In the case of ethash PoW, this means mining new blocks, as specified by Ethereum.
    # In the general case, the semantics are due to the specific consensus implementation.
    mining-enabled = false
  }

  # This is the section dedicated to Ethash mining.
  # This consensus protocol is selected by setting `mantis.consensus.protocol = ethash`.
  ethash {
    # Maximum number of ommers kept in the pool
    ommers-pool-size = 30

    ommer-pool-query-timeout = 5.seconds

    ethash-dir = ${user.home}"/.ethash"

    mine-rounds = 100000
  }

  # This is the section dedicated to `atomix-raft` consensus.
  # This consensus protocol is selected by setting `mantis.consensus.protocol = atomix-raft`.
  atomix-raft {
    election-timeout = 3.minutes

    heartbeat-interval = 300.millis

    # Determines how often new blocks will be forged
    block-forging-delay = 15.seconds

    # Represents this node.
    #
    # ID and PORT are not mandatory.
    # If PORT is not given, then is assumes the value of
    # io.atomix.messaging.impl.NettyMessagingService.DEFAULT_PORT, which currently is 5679.
    # If ID is not given, then its value becomes IP_PORT.
    local-node = "ID:IP:PORT"

    # All the other nodes in the cluster, in the same format as with `local-node`.
    bootstrap-nodes = [
      "ID1:IP:PORT",
      "ID2:IP:PORT",
      "ID3:IP:PORT"
    ]

    # Transient data directory
    data-dir = ${mantis.datadir}"/atomix-raft-data"
  }

  blockchain {
    # Frontier block number
    frontier-block-number = "0"

    # Homestead fork block number
    # Doc: https://github.com/ethereum/EIPs/blob/master/EIPS/eip-2.md
    homestead-block-number = "1150000"

    # EIP-106 fork block number
    # Doc: https://github.com/ethereum/EIPs/issues/106
    eip106-block-number = "1000000000000000000"

    # EIP-150 fork block number
    # Doc: https://github.com/ethereum/EIPs/issues/150
    eip150-block-number = "2500000"

    # EIP-155 fork block number
    # Doc: https://github.com/ethereum/eips/issues/155
    # 3 000 000 following lead of existing clients implementation to maintain compatibility
    # https://github.com/paritytech/parity/blob/b50fb71dd1d29dfde2a6c7e1830447cf30896c31/ethcore/res/ethereum/classic.json#L15
    eip155-block-number = "3000000"

    # EIP-160 fork block number
    # Doc: https://github.com/ethereum/EIPs/issues/160
    eip160-block-number = "3000000"

    # EIP-161 fork block number (ETH Only)
    # Doc: https://github.com/ethereum/EIPs/blob/master/EIPS/eip-161.md
    eip161-block-number = "1000000000000000000"

    # EIP-170 max code size (Eth only)
    # Doc: https://github.com/ethereum/EIPs/issues/170
    # null value indicates there's no max code size for the contract code
    max-code-size = null

    # Difficulty bomb pause block number
    # Doc: https://github.com/ethereumproject/ECIPs/blob/master/ECIPs/ECIP-1010.md
    difficulty-bomb-pause-block-number = "3000000"

    # Difficulty bomb continuation block number
    # Doc: https://github.com/ethereumproject/ECIPs/blob/master/ECIPs/ECIP-1010.md
    difficulty-bomb-continue-block-number = "5000000"

    # Difficulty bomb defusion block number
    # Doc: https://github.com/ethereumproject/ECIPs/blob/master/ECIPs/ECIP-1041.md
    difficulty-bomb-removal-block-number = "5900000"

    # Byzantium fork block number (ETH only)
    # https://github.com/ethereum/EIPs/blob/master/EIPS/eip-609.md
    byzantium-block-number = "1000000000000000000"

    # DAO fork configuration (Ethereum HF/Classic split)
    # https://blog.ethereum.org/2016/07/20/hard-fork-completed/
    dao {
      # DAO fork block number
      fork-block-number = "1920000"

      # The hash of the accepted DAO fork block
      fork-block-hash = "94365e3a8c0b35089c1d1195081fe7489b528a84b22199c916180db8b28ade7f"

      # Extra data to be put in fork block headers
      block-extra-data = null

      # number of blocks to place extra data after fork
      block-extra-data-range = 10

      # Address to send funds when draining
      refund-contract-address = null

      # List of accounts to be drained
      drain-list = null
    }

    # Starting nonce a an empty account. Some networks (like Morden) use different values.
    account-start-nonce = "0"

    # The ID of the accepted chain
    chain-id = "0x3d"

    # Custom genesis JSON file path
    # null value indicates using default genesis definition that matches the main network
    custom-genesis-file = null

    # Monetary policy parameters
    # Doc: https://github.com/ethereumproject/ECIPs/blob/master/ECIPs/ECIP-1017.md
    monetary-policy {
      # Block reward in the first era
      first-era-block-reward = "5000000000000000000"

      # Reduced block reward after Byzantium fork
      first-era-reduced-block-reward = "3000000000000000000"

      # Monetary policy era duration in number of blocks
      era-duration = 5000000

      # Rate at which rewards get reduced in successive eras.
      # Value in range [0.0, 1.0]
      reward-reduction-rate = 0.2
    }

    # if 2 competing blocktree branches are equal in terms of total difficulty and this is set to true, then gas
    # consumed in those branches will be used to resolve the tie
    # this is currently only used in ETS blockchain tests
    gas-tie-breaker = false

    # if true, account storage will use Ethereum-specific format for storing keys/value in MPT (32 byte)
    # if false, generic storage for arbitrary length integers will be used
    eth-compatible-storage = true
  }

  sync {
    # Whether to enable fast-sync
    do-fast-sync = true

    # Interval for updating peers during sync
    peers-scan-interval = 3.seconds

    # Duration for blacklisting a peer. Blacklisting reason include: invalid response from peer, response time-out, etc.
    # 0 value is a valid duration and it will disable blacklisting completely (which can be useful when all nodes are
    # are controlled by a single party, eg. private networks)
    blacklist-duration = 200.seconds

    # Retry interval when not having enough peers to start fast-sync
    start-retry-interval = 5.seconds

    # Retry interval for resuming fast sync after all connections to peers were lost
    sync-retry-interval = 5.seconds

    # Response time-out from peer during sync. If a peer fails to respond within this limit, it will be blacklisted
    peer-response-timeout = 3.minutes

    # Interval for logging syncing status info
    print-status-interval = 30.seconds

    # How often to dump fast-sync status to disk. If the client is restarted, fast-sync will continue from this point
    persist-state-snapshot-interval = 1.minute

    # Maximum concurrent requests when in fast-sync mode
    max-concurrent-requests = 50

    # Requested number of block headers when syncing from other peers
    block-headers-per-request = 200

    # Requested number of block bodies when syncing from other peers
    block-bodies-per-request = 128

    # Requested number of TX receipts when syncing from other peers
    receipts-per-request = 60

    # Requested number of MPT nodes when syncing from other peers
    nodes-per-request = 384

    # Minimum number of peers required to start fast-sync (by determining the target block)
    min-peers-to-choose-target-block = 2

    # During fast-sync when most up to date block is determined from peers, the actual target block number
    # will be decreased by this value
    target-block-offset = 500

    # How often to query peers for new blocks after the top of the chain has been reached
    check-for-new-block-interval = 10.seconds

    # size of the list that keeps track of peers that are failing to provide us with mpt node
    # we switch them to download only blockchain elements
    fastsync-block-chain-only-peers-pool = 100

    # time between 2 consecutive requests to peer when doing fast sync, this is to prevent flagging us as spammer
    fastsync-throttle = 0.3 seconds

    # When we receive a branch that is not rooted in our chain (we don't have a parent for the first header), it means
    # we found a fork. To resolve it, we need to query the same peer for previous headers, to find a common ancestor.
    # This setting determines how many additional headers we request. The default of 12 may be regarded as confirmation
    # depth in ethereum (https://www.reddit.com/r/ethereum/comments/4eplsv/how_many_confirms_is_considered_safe_in_ethereum/)
    branch-resolution-request-size = 12

    # threshold for storing non-main-chain blocks in queue.
    # if: current_best_block_number - block_number > max-queued-block-number-behind
    # then: the block will not be queued (such already queued blocks will be removed)
    max-queued-block-number-behind = 10

    # threshold for storing non-main-chain blocks in queue.
    # if: block_number - current_best_block_number > max-queued-block-number-ahead
    # then: the block will not be queued (such already queued blocks will be removed)
    max-queued-block-number-ahead = 10

    # Maximum number of blocks, after which block hash from NewBlockHashes packet is considered ancient
    # and peer sending it is blacklisted
    max-new-block-hash-age = 20

    # Maximum number of hashes processed form NewBlockHashes packet
    max-new-hashes = 64

    # Set to false to disable broadcasting the NewBlockHashes message, as its usefulness is debatable,
    # especially in the context of private networks
    broadcast-new-block-hashes = true

    # This a recovery mechanism for the issue of missing state nodes during blocks execution:
    # off - missing state node will result in an exception
    # on - missing state node will be redownloaded from a peer and block execution will be retried. This can repeat
    #      several times until block execution succeeds
    redownload-missing-state-nodes = on

    # See: https://github.com/ethereum/go-ethereum/pull/1889
    fast-sync-block-validation-k = 100
    fast-sync-block-validation-n = 2048
    fast-sync-block-validation-x = 24

    # Maxium difference beetween our target block and best possible target block (current best known block - offset)
    # This is to ensure that we start downloading our state as close as possible to top of the chain
    max-target-difference = 20

    # Maxium number of failure to update target block, this could happen when target block, or x blocks  after target
    # fail validation. Or when we keep getting old block from the network.
    maximum-target-update-failures = 5
  }

  pruning {
    # Pruning mode that the application will use.
    #
    # - archive: No pruning is performed
    # - basic: reference count based pruning
    #
    # After changing, please delete previous db before starting the client:
    #
    mode = "basic"

    # The amount of block history kept before pruning
    # Note: if fast-sync clients choose target block offset greater than this value, mantis may not be able to
    # correctly act as a fast-sync server
    history = 64
  }

  db {
    # IODB database is not currently used
    iodb {
      path = ${mantis.datadir}"/iodb/"
    }

    leveldb {
      # LevelDB data directory
      path = ${mantis.datadir}"/leveldb/"

      # Create DB data directory if it's missing
      create-if-missing = true

      # Should the DB raise an error as soon as it detects an internal corruption
      paranoid-checks = true

      # Force checksum verification of all data that is read from the file system on behalf of a particular read
      verify-checksums = true

      # Native LevelDB (via JNI) or LevelDB Java port.
      native = true

      # This ensures that only 32 open files can be accessed at once
      max-open-files = 32
    }

    rocksdb {
      # RocksDB data directory
      path = ${mantis.datadir}"/rocksdb/"

      # Create DB data directory if it's missing
      create-if-missing = true

      # Should the DB raise an error as soon as it detects an internal corruption
      paranoid-checks = true

      # This ensures that only one thread will be occupied
      max-threads = 1

      # This ensures that only 32 open files can be accessed at once
      max-open-files = 32

      # Force checksum verification of all data that is read from the file system on behalf of a particular read
      verify-checksums = true

      # Can be turned on to make the write operation not return until the data being written has been pushed all the way to persistent storage
      synchronous-writes = false
    }

    # Define which database to use [leveldb, rocksdb], iodb is not currently used
    data-source = "rocksdb"
  }

  node-caching {

    # Maximum number of nodes kept in cache
    # Each key-value pair of nodeHash-Nodencode has around ~600bytes, so cache around ~250Mb equals to 400000 key-value pairs
    max-size = 400000


    # Time after which we flush all data in cache to underlying storage
    # This ensures that in case of quit we lose at most ~5 min of work
    max-hold-time = 5.minutes
  }

  filter {
    # Time at which a filter remains valid
    filter-timeout = 10.minutes

    filter-manager-query-timeout = 3.minutes
  }

  vm {
    # internal | external
    mode = "internal"

    external {
      # possible values are:
      # - iele: runs a binary provided at `executable-path` with `port` and `host` as arguments (`./executable-path $port $host`)
      # - kevm: runs a binary provided at `executable-path` with `port` and `host` as arguments (`./executable-path $port $host`)
      # - mantis: if `executable-path` is provided, it will run the binary with `port` and `host` as arguments
      #           otherwise mantis VM will be run in the same process, but acting as an external VM (listening at `host` and `port`)
      # - none: doesn't run anything, expect the VM to be started by other means
      vm-type = "mantis"

      # path to the executable - optional depending on the `vm-type` setting
      executable-path = "./bin/mantis-vm"

      host = "127.0.0.1"
      port = 8888
    }
  }

  metrics {
    # Set to `true` iff your deployment supports metrics collection.
    # We push metrics to a StatsD-compatible agent and we use Datadog for collecting them in one place.
    # We default to `false` here because we do not expect all deployments to support metrics collection.
    enabled = false

    # The StatsD-compatible agent host.
    host = "localhost"

    # The StatsD-compatible agent port.
    port = 8125

    # All metrics sent will be tagged with the environment.
    # Sample values are: `public`, `private`, `production`, `dev`, depending on the use-case.
    # If metrics are `enabled`, this is mandatory and must be set explicitly to a non-null value.
    #
    # environment = null

    # All metrics sent will be tagged with the deployment.
    # Sample values are: `kevm-testnet`, `iele-testnet`, `raft-kevm`, depending on the use-case.
    # If metrics are `enabled`, this is mandatory and must be set explicitly to a non-null value.
    #
    # deployment = null

    # Size of the metrics requests queue.
    # If the queue contains that many outstanding requests to the metrics agent, then
    # subsequent requests are blocked until the queue has room again.
    queue-size = 1024

    # Iff true, any errors during metrics client operations will be logged.
    log-errors = true
  }
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  logger-startup-timeout = 30s
  log-dead-letters = off
}
